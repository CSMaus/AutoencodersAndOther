{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de18ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.optimizers\n",
    "import numpy as np, os, pathlib, matplotlib.pyplot as plt, sys, seaborn as sns\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, Flatten, Reshape, Lambda, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Rescaling, Reshape, Resizing, RandomZoom, RandomRotation, RandomFlip\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.metrics.metrics import binary_crossentropy\n",
    "from keras.layers import LeakyReLU, Conv2D, MaxPool2D, UpSampling2D, RepeatVector, MaxPooling2D\n",
    "from keras import backend as bk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d65787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "batch_size = 240\n",
    "latent_dim = 512  # to be easier generate and visualize result\n",
    "dropout_r = 0.1\n",
    "lr_0 = 0.0001\n",
    "epoch = 10\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "ims = 224\n",
    "\n",
    "Adam = keras.optimizers.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b233963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 4800\n"
     ]
    }
   ],
   "source": [
    "name = f'pets_cvae_dim{latent_dim}_epochs{epoch}_ims{ims}'\n",
    "\n",
    "data_dir = 'D:/DataSets/dogs_cats'\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print('Number of images:', image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "418b338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH SIZE: 240\n"
     ]
    }
   ],
   "source": [
    "if batch_size < image_count:\n",
    "    batch_size = int(image_count * 0.05)\n",
    "    # print(batch_size)\n",
    "else:\n",
    "    batch_size = image_count // 2\n",
    "\n",
    "print('BATCH SIZE:', batch_size)\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c7b7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4800 files belonging to 2 classes.\n",
      "Using 3840 files for training.\n",
      "Found 4800 files belonging to 2 classes.\n",
      "Using 960 files for validation.\n",
      "num_classes: 2 - ['cats', 'dogs']\n",
      "\n",
      "\n",
      "shape train_img, train_lbl: (3840, 224, 224, 3) (3840, 2) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(ims, ims),\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode=\"rgb\"\n",
    ")\n",
    "\n",
    "valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(ims, ims),\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode=\"rgb\"\n",
    ")\n",
    "\n",
    "ishape = (ims, ims, 3)\n",
    "class_names = train_ds.class_names  # os.listdir(os.path.join(data_dir))\n",
    "num_classes = len(class_names)\n",
    "print('num_classes:', num_classes, '-', class_names)\n",
    "\n",
    "\n",
    "full_imgs = lambda ds: np.concatenate([x for x, y in ds])\n",
    "full_lbls = lambda ds: np.concatenate([y for x, y in ds])\n",
    "\n",
    "train_img = full_imgs(train_ds)\n",
    "train_img = train_img.astype('float32') / 255.\n",
    "train_lbl = full_lbls(train_ds)\n",
    "# train_lbl_cat = tf.keras.utils.to_categorical(train_lbl).astype(np.float32)\n",
    "\n",
    "valid_img = full_imgs(valid_ds)\n",
    "valid_img = valid_img.astype('float32') / 255.\n",
    "valid_lbl = full_lbls(valid_ds)\n",
    "print('\\n\\nshape train_img, train_lbl:', np.shape(train_img), np.shape(train_lbl), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f356941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_units_to_conv2d(conv2, units):\n",
    "    dim1 = int(conv2.shape[1])\n",
    "    dim2 = int(conv2.shape[2])\n",
    "    dimc = int(units.shape[1])\n",
    "    repeat_n = dim1 * dim2\n",
    "    units_repeat = RepeatVector(repeat_n)(units)  # lbl -> units\n",
    "    units_repeat = Reshape((dim1, dim2, dimc))(units_repeat)\n",
    "    return concatenate([conv2, units_repeat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a47178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cvae():\n",
    "    models = {}\n",
    "\n",
    "    def apply_bn_and_dropout(x):\n",
    "        return Dropout(dropout_r)(BatchNormalization()(x))\n",
    "\n",
    "    # Encoder\n",
    "    inp_img = Input(shape=ishape)  # batch_shape=(batch_size, ims, ims, 1)\n",
    "    # flat = Flatten()(inp_img)\n",
    "    inp_lbls = Input(shape=(num_classes,), dtype='float32')\n",
    "    # print('shape of inp_lbls 0, 1', inp_lbls.shape[0], inp_lbls.shape[1])\n",
    "\n",
    "    x = Conv2D(64, (7, 7), activation='relu', padding='same')(inp_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = add_units_to_conv2d(x, inp_lbls)\n",
    "    x = Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    enc = Conv2D(3, (7, 7), activation='relu', padding='same')(x)\n",
    "    x = Flatten()(enc)\n",
    "\n",
    "    # predict logarithm of variation instead of standard deviation\n",
    "    z_mean = Dense(latent_dim)(x)\n",
    "    z_log_var = Dense(latent_dim)(x)\n",
    "    print('\\n\\nshape of z_mean [0], [1]:', z_mean.shape[0], z_mean.shape[1], '\\n')\n",
    "\n",
    "    # sampling from Q with reparametrisation\n",
    "    def sampling(args):\n",
    "        z_means, z_log_vars = args\n",
    "        epsilon = bk.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.0)\n",
    "        return z_means + bk.exp(z_log_vars / 2) * epsilon\n",
    "\n",
    "    l = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "    l_z = concatenate([l, inp_lbls])\n",
    "    # l_z = concatenate([z_mean, inp_lbls])\n",
    "\n",
    "    encoder = Model([inp_img, inp_lbls], l_z, name='my_encoder')\n",
    "    encoder.summary()\n",
    "    z_meaner = Model([inp_img, inp_lbls], z_mean, name='Enc_z_mean')\n",
    "    models[\"encoder\"] = encoder\n",
    "    models[\"z_meaner\"] = z_meaner\n",
    "    # models[\"z_lvarer\"] = Model([inp_img, inp_lbls], z_log_var, name='Enc_z_log_var')\n",
    "\n",
    "    # Decoder\n",
    "    z = Input(shape=(latent_dim + num_classes,))\n",
    "    # x = concatenate([z, lbl])\n",
    "\n",
    "    nn = int(ims // 56)  # 28\n",
    "    bs = int(batch_size // 2)\n",
    "    x = Dense(7 * 2 * 7 * 2 * 8, activation='relu', name='decoder_dense_1')(z)\n",
    "    x = Reshape((7 * 2, 7 * 2, 8))(x)\n",
    "    x = Conv2D(32, kernel_size=(7, 7), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (5, 5), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(3, (7, 7), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    decoder = Model(z, decoded, name='my_decoder')  # [z, inp_lbls_d]\n",
    "    decoder.summary()\n",
    "    models[\"decoder\"] = decoder\n",
    "\n",
    "    cvae_out = decoder(encoder([inp_img, inp_lbls]))\n",
    "\n",
    "    my_cvae = Model([inp_img, inp_lbls], cvae_out, name='my_cvae')\n",
    "    models['cvae'] = my_cvae\n",
    "\n",
    "    out_style = decoder(concatenate([z_meaner([inp_img, inp_lbls]), inp_lbls]))\n",
    "    models[\"style_t\"] = Model([inp_img, inp_lbls], out_style, name=\"style_transfer\")\n",
    "\n",
    "    def vae_loss(xf, decodedf):\n",
    "        xf = bk.reshape(xf, shape=(batch_size, ims * ims * 3))\n",
    "        decodedf = bk.reshape(decodedf, shape=(batch_size, ims * ims * 3))\n",
    "        xent_loss = ims * ims * 3 * binary_crossentropy(xf, decodedf)\n",
    "        kl_loss = -0.5 * bk.sum(1 + z_log_var - bk.square(z_mean) - bk.exp(z_log_var), axis=-1)\n",
    "        return (xent_loss + kl_loss) / 2 / ims / ims / 3\n",
    "\n",
    "    return models, vae_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "521a4a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "shape of z_mean [0], [1]: None 512 \n",
      "\n",
      "Model: \"my_encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 224, 224, 64  9472        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 12544, 2)     0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 112, 112, 64  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 112, 112, 2)  0           ['repeat_vector[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 112, 112, 66  0           ['max_pooling2d[0][0]',          \n",
      "                                )                                 'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 112, 112, 32  52832       ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 32)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 56, 56, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 64)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 28, 28, 128)  73856       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 128)  0          ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 14, 14, 3)    18819       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 588)          0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          301568      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          301568      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (240, 512)           0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (240, 514)           0           ['lambda[0][0]',                 \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 776,611\n",
      "Trainable params: 776,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"my_decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 514)]             0         \n",
      "                                                                 \n",
      " decoder_dense_1 (Dense)     (None, 1568)              807520    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 32)        12576     \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 28, 28, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 56, 56, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 112, 112, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 112, 112, 128)     409728    \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 224, 224, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 224, 224, 3)       18819     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,340,995\n",
      "Trainable params: 1,340,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cvae_models, cvae_losses = create_cvae()\n",
    "cvae = cvae_models[\"cvae\"]\n",
    "\n",
    "cvae.compile(optimizer='adam', loss='binary_crossentropy', experimental_run_tf_function=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e245bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from keras.callbacks import LambdaCallback, ReduceLROnPlateau, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b5a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = [[] for x in range(num_classes)]\n",
    "latent_distrs = [[] for x in range(num_classes)]\n",
    "epochs = []\n",
    "\n",
    "# Saves epoches\n",
    "save_epochs = set(list((np.arange(0, 59) ** 1.701).astype(int)) + list(range(10)))\n",
    "\n",
    "n_compare = 10\n",
    "\n",
    "# Models\n",
    "generator = cvae_models[\"decoder\"]\n",
    "encoder_mean = cvae_models[\"z_meaner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e2cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "tb = TensorBoard(log_dir=f'logs/{name}')\n",
    "\n",
    "# Run training\n",
    "# disable_eager_execution()\n",
    "\n",
    "cvae.fit(\n",
    "    x=[train_img, train_lbl],\n",
    "    y=train_img,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    epochs=epoch,\n",
    "    validation_data=([valid_img, valid_lbl], valid_img),\n",
    "    callbacks=[tb],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89591346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(*args, invert_colors=False):\n",
    "    args = [x.squeeze() for x in args]\n",
    "    n_f = min([x.shape[0] for x in args])\n",
    "    figure = np.zeros((ims * len(args), ims * n_f, 3))\n",
    "\n",
    "    for i in range(n_f):\n",
    "        for j in range(len(args)):\n",
    "            figure[j * ims: (j + 1) * ims,\n",
    "            i * ims: (i + 1) * ims, :] = args[j][i].squeeze()\n",
    "\n",
    "    if invert_colors:\n",
    "        figure = 1 - figure\n",
    "\n",
    "    plt.figure(figsize=(2 * n_f, 2 * len(args)))\n",
    "    plt.imshow(figure)  # cmap='Greys_r'\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f233c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "n = 5\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_z_distr(z_predicted, lbl):\n",
    "    input_lbl = np.zeros((1, 10))\n",
    "    input_lbl[0, lbl] = 1\n",
    "    im = plt.scatter(z_predicted[:, 0], z_predicted[:, 1])\n",
    "    im.axes.set_xlim(-5, 5)\n",
    "    im.axes.set_ylim(-5, 5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def style_transfer(model, X, lbl_in, lbl_out):\n",
    "    rows = X.shape[0]\n",
    "    if isinstance(lbl_in, int):\n",
    "        lbl_f = lbl_in\n",
    "        lbl_in = np.zeros((rows, 2))\n",
    "        lbl_in[:, lbl_f] = 1\n",
    "    if isinstance(lbl_out, int):\n",
    "        lbl_f = lbl_out\n",
    "        lbl_out = np.zeros((rows, 2))\n",
    "        lbl_out[:, lbl_f] = 1\n",
    "    return model.predict([X, lbl_in, lbl_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25837604",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = 1\n",
    "generated = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be69853",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_classes):\n",
    "    print(i)\n",
    "    prot = train_img[train_lbl.T[0] == i][:n]\n",
    "    generated.append(style_transfer(cvae_models[\"style_t\"], prot, lbl, i))\n",
    "\n",
    "prot = train_img[train_lbl.T[0] == lbl][:n]\n",
    "generated[lbl] = prot\n",
    "plot_images(*generated, invert_colors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(imgs))\n",
    "print(imgs.shape)\n",
    "decoded = cvae.predict([imgs, imgs_lbls], batch_size=batch_size)\n",
    "plot_images(imgs[:n_compare], decoded[:n_compare])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f73d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f7f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f92fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e50c30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd955aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
